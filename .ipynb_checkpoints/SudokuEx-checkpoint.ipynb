{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d9b35f-0073-4048-a964-d6d15313373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# from NumberExtractor import extract_number\n",
    "\n",
    "\n",
    "def plot_many_images(images, titles, rows=1, columns=2):\n",
    "    \"\"\"Plots each image in a given list as a grid structure. using Matplotlib.\"\"\"\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, columns, i+1)\n",
    "        plt.imshow(image, 'gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks([]), plt.yticks([])  # Hide tick marks\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    \"\"\"Shows an image until any key is pressed\"\"\"\n",
    "#    print(type(img))\n",
    "#    print(img.shape)\n",
    "#    cv2.imshow('image', img)  # Display the image\n",
    "#    cv2.imwrite('images/gau_sudoku3.jpg', img)\n",
    "#    cv2.waitKey(0)  # Wait for any key to be pressed (with the image window active)\n",
    "#    cv2.destroyAllWindows()  # Close all windows\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_digits(digits, colour=255):\n",
    "    \"\"\"Shows list of 81 extracted digits in a grid format\"\"\"\n",
    "    rows = []\n",
    "    with_border = [cv2.copyMakeBorder(img.copy(), 1, 1, 1, 1, cv2.BORDER_CONSTANT, None, colour) for img in digits]\n",
    "    for i in range(9):\n",
    "        row = np.concatenate(with_border[i * 9:((i + 1) * 9)], axis=1)\n",
    "        rows.append(row)\n",
    "    img = show_image(np.concatenate(rows))\n",
    "    return img\n",
    " \n",
    "\n",
    "def convert_when_colour(colour, img):\n",
    "    \"\"\"Dynamically converts an image to colour if the input colour is a tuple and the image is grayscale.\"\"\"\n",
    "    if len(colour) == 3:\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def display_points(in_img, points, radius=5, colour=(0, 0, 255)):\n",
    "    \"\"\"Draws circular points on an image.\"\"\"\n",
    "    img = in_img.copy()\n",
    "\n",
    "    # Dynamically change to a colour image if necessary\n",
    "    if len(colour) == 3:\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for point in points:\n",
    "        img = cv2.circle(img, tuple(int(x) for x in point), radius, colour, -1)\n",
    "    show_image(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def display_rects(in_img, rects, colour=(0, 0, 255)):\n",
    "    \"\"\"Displays rectangles on the image.\"\"\"\n",
    "    img = convert_when_colour(colour, in_img.copy())\n",
    "    for rect in rects:\n",
    "        img = cv2.rectangle(img, tuple(int(x) for x in rect[0]), tuple(int(x) for x in rect[1]), colour)\n",
    "    show_image(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def display_contours(in_img, contours, colour=(0, 0, 255), thickness=2):\n",
    "    \"\"\"Displays contours on the image.\"\"\"\n",
    "    img = convert_when_colour(colour, in_img.copy())\n",
    "    img = cv2.drawContours(img, contours, -1, colour, thickness)\n",
    "    show_image(img)\n",
    "\n",
    "\n",
    "def pre_process_image(img, skip_dilate=False):\n",
    "    \"\"\"Uses a blurring function, adaptive thresholding and dilation to expose the main features of an image.\"\"\"\n",
    "\n",
    "    # Gaussian blur with a kernal size (height, width) of 9.\n",
    "    # Note that kernal sizes must be positive and odd and the kernel must be square.\n",
    "    \n",
    "    img2 = img.copy()\n",
    "    proc = cv2.GaussianBlur(img2, (9, 9), 0)\n",
    "\n",
    "    # Adaptive threshold using 11 nearest neighbour pixels\n",
    "    proc = cv2.adaptiveThreshold(proc, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Invert colours, so gridlines have non-zero pixel values.\n",
    "    # Necessary to dilate the image, otherwise will look like erosion instead.\n",
    "    proc = cv2.bitwise_not(proc, proc)\n",
    "\n",
    "    if not skip_dilate:\n",
    "        # Dilate the image to increase the size of the grid lines.\n",
    "        kernel = np.array([[0., 1., 0.], [1., 1., 1.], [0., 1., 0.]],np.uint8)\n",
    "        proc = cv2.dilate(proc, kernel)\n",
    "\n",
    "    return proc\n",
    "\n",
    "\n",
    "def find_corners_of_largest_polygon(img):\n",
    "    \"\"\"Finds the 4 extreme corners of the largest contour in the image.\"\"\"\n",
    "    opencv_version = cv2.__version__.split('.')[0]\n",
    "    if opencv_version == '3':\n",
    "        _, contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "    else:\n",
    "        contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)  # Sort by area, descending\n",
    "    polygon = contours[0]  # Largest image\n",
    "\n",
    "    # Use of `operator.itemgetter` with `max` and `min` allows us to get the index of the point\n",
    "    # Each point is an array of 1 coordinate, hence the [0] getter, then [0] or [1] used to get x and y respectively.\n",
    "\n",
    "    # Bottom-right point has the largest (x + y) value\n",
    "    # Top-left has point smallest (x + y) value\n",
    "    # Bottom-left point has smallest (x - y) value\n",
    "    # Top-right point has largest (x - y) value\n",
    "    bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\n",
    "    # Return an array of all 4 points using the indices\n",
    "    # Each point is in its own array of one coordinate\n",
    "    return [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]\n",
    "\n",
    "\n",
    "def distance_between(p1, p2):\n",
    "    \"\"\"Returns the scalar distance between two points\"\"\"\n",
    "    a = p2[0] - p1[0]\n",
    "    b = p2[1] - p1[1]\n",
    "    return np.sqrt((a ** 2) + (b ** 2))\n",
    "\n",
    "\n",
    "def crop_and_warp(img, crop_rect):\n",
    "    \"\"\"Crops and warps a rectangular section from an image into a square of similar size.\"\"\"\n",
    "\n",
    "    # Rectangle described by top left, top right, bottom right and bottom left points\n",
    "    top_left, top_right, bottom_right, bottom_left = crop_rect[0], crop_rect[1], crop_rect[2], crop_rect[3]\n",
    "\n",
    "    # Explicitly set the data type to float32 or `getPerspectiveTransform` will throw an error\n",
    "    src = np.array([top_left, top_right, bottom_right, bottom_left], dtype='float32')\n",
    "\n",
    "    # Get the longest side in the rectangle\n",
    "    side = max([\n",
    "        distance_between(bottom_right, top_right),\n",
    "        distance_between(top_left, bottom_left),\n",
    "        distance_between(bottom_right, bottom_left),\n",
    "        distance_between(top_left, top_right)\n",
    "    ])\n",
    "\n",
    "    # Describe a square with side of the calculated length, this is the new perspective we want to warp to\n",
    "    dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "    # Gets the transformation matrix for skewing the image to fit a square by comparing the 4 before and after points\n",
    "    m = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Performs the transformation on the original image\n",
    "    return cv2.warpPerspective(img, m, (int(side), int(side)))\n",
    "\n",
    "\n",
    "def infer_grid(img):\n",
    "    \"\"\"Infers 81 cell grid from a square image.\"\"\"\n",
    "    squares = []\n",
    "    side = img.shape[:1]\n",
    "    side = side[0] / 9\n",
    "\n",
    "    # Note that we swap j and i here so the rectangles are stored in the list reading left-right instead of top-down.\n",
    "    for j in range(9):\n",
    "        for i in range(9):\n",
    "            p1 = (i * side, j * side)  # Top left corner of a bounding box\n",
    "            p2 = ((i + 1) * side, (j + 1) * side)  # Bottom right corner of bounding box\n",
    "            squares.append((p1, p2))\n",
    "    return squares\n",
    "\n",
    "\n",
    "def cut_from_rect(img, rect):\n",
    "    \"\"\"Cuts a rectangle from an image using the top left and bottom right points.\"\"\"\n",
    "    return img[int(rect[0][1]):int(rect[1][1]), int(rect[0][0]):int(rect[1][0])]\n",
    "\n",
    "\n",
    "def scale_and_centre(img, size, margin=0, background=0):\n",
    "    \"\"\"Scales and centres an image onto a new background square.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    def centre_pad(length):\n",
    "        \"\"\"Handles centering for a given length that may be odd or even.\"\"\"\n",
    "        if length % 2 == 0:\n",
    "            side1 = int((size - length) / 2)\n",
    "            side2 = side1\n",
    "        else:\n",
    "            side1 = int((size - length) / 2)\n",
    "            side2 = side1 + 1\n",
    "        return side1, side2\n",
    "\n",
    "    def scale(r, x):\n",
    "        return int(r * x)\n",
    "\n",
    "    if h > w:\n",
    "        t_pad = int(margin / 2)\n",
    "        b_pad = t_pad\n",
    "        ratio = (size - margin) / h\n",
    "        w, h = scale(ratio, w), scale(ratio, h)\n",
    "        l_pad, r_pad = centre_pad(w)\n",
    "    else:\n",
    "        l_pad = int(margin / 2)\n",
    "        r_pad = l_pad\n",
    "        ratio = (size - margin) / w\n",
    "        w, h = scale(ratio, w), scale(ratio, h)\n",
    "        t_pad, b_pad = centre_pad(h)\n",
    "\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = cv2.copyMakeBorder(img, t_pad, b_pad, l_pad, r_pad, cv2.BORDER_CONSTANT, None, background)\n",
    "    return cv2.resize(img, (size, size))\n",
    "\n",
    "\n",
    "def find_largest_feature(inp_img, scan_tl=None, scan_br=None):\n",
    "    \"\"\"\n",
    "    Uses the fact the `floodFill` function returns a bounding box of the area it filled to find the biggest\n",
    "    connected pixel structure in the image. Fills this structure in white, reducing the rest to black.\n",
    "    \"\"\"\n",
    "    img = inp_img.copy()  # Copy the image, leaving the original untouched\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    max_area = 0\n",
    "    seed_point = (None, None)\n",
    "\n",
    "    if scan_tl is None:\n",
    "        scan_tl = [0, 0]\n",
    "\n",
    "    if scan_br is None:\n",
    "        scan_br = [width, height]\n",
    "\n",
    "    # Loop through the image\n",
    "    for x in range(scan_tl[0], scan_br[0]):\n",
    "        for y in range(scan_tl[1], scan_br[1]):\n",
    "            # Only operate on light or white squares\n",
    "            if img.item(y, x) == 255 and x < width and y < height:  # Note that .item() appears to take input as y, x\n",
    "                area = cv2.floodFill(img, None, (x, y), 64)\n",
    "                if area[0] > max_area:  # Gets the maximum bound area which should be the grid\n",
    "                    max_area = area[0]\n",
    "                    seed_point = (x, y)\n",
    "\n",
    "    # Colour everything grey (compensates for features outside of our middle scanning range\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            if img.item(y, x) == 255 and x < width and y < height:\n",
    "                cv2.floodFill(img, None, (x, y), 64)\n",
    "\n",
    "    mask = np.zeros((height + 2, width + 2), np.uint8)  # Mask that is 2 pixels bigger than the image\n",
    "\n",
    "    # Highlight the main feature\n",
    "    if all([p is not None for p in seed_point]):\n",
    "        cv2.floodFill(img, mask, seed_point, 255)\n",
    "\n",
    "    top, bottom, left, right = height, 0, width, 0\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            if img.item(y, x) == 64:  # Hide anything that isn't the main feature\n",
    "                cv2.floodFill(img, mask, (x, y), 0)\n",
    "\n",
    "            # Find the bounding parameters\n",
    "            if img.item(y, x) == 255:\n",
    "                top = y if y < top else top\n",
    "                bottom = y if y > bottom else bottom\n",
    "                left = x if x < left else left\n",
    "                right = x if x > right else right\n",
    "\n",
    "    bbox = [[left, top], [right, bottom]]\n",
    "    return img, np.array(bbox, dtype='float32'), seed_point\n",
    "\n",
    "\n",
    "def extract_digit(img, rect, size):\n",
    "    \"\"\"Extracts a digit (if one exists) from a Sudoku square.\"\"\"\n",
    "\n",
    "    digit = cut_from_rect(img, rect)  # Get the digit box from the whole square\n",
    "\n",
    "    # Use fill feature finding to get the largest feature in middle of the box\n",
    "    # Margin used to define an area in the middle we would expect to find a pixel belonging to the digit\n",
    "    h, w = digit.shape[:2]\n",
    "    margin = int(np.mean([h, w]) / 2.5)\n",
    "    _, bbox, seed = find_largest_feature(digit, [margin, margin], [w - margin, h - margin])\n",
    "    digit = cut_from_rect(digit, bbox)\n",
    "\n",
    "    # Scale and pad the digit so that it fits a square of the digit size we're using for machine learning\n",
    "    w = bbox[1][0] - bbox[0][0]\n",
    "    h = bbox[1][1] - bbox[0][1]\n",
    "\n",
    "    # Ignore any small bounding boxes\n",
    "    if w > 0 and h > 0 and (w * h) > 100 and len(digit) > 0:\n",
    "        return scale_and_centre(digit, size, 4)\n",
    "    else:\n",
    "        return np.zeros((size, size), np.uint8)\n",
    "\n",
    "\n",
    "def get_digits(img, squares, size):\n",
    "    \"\"\"Extracts digits from their cells and builds an array\"\"\"\n",
    "    digits = []\n",
    "    img = pre_process_image(img.copy(), skip_dilate=True)\n",
    "#    cv2.imshow('img', img)\n",
    "    for square in squares:\n",
    "        digits.append(extract_digit(img, square, size))\n",
    "    return digits\n",
    "\n",
    "\n",
    "def parse_grid(path):\n",
    "    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    processed = pre_process_image(original)\n",
    "    \n",
    "#    cv2.namedWindow('processed',cv2.WINDOW_AUTOSIZE)\n",
    "#    processed_img = cv2.resize(processed, (500, 500))          # Resize image\n",
    "#    cv2.imshow('processed', processed_img)\n",
    "    \n",
    "    corners = find_corners_of_largest_polygon(processed)\n",
    "    cropped = crop_and_warp(original, corners)\n",
    "    \n",
    "#    cv2.namedWindow('cropped',cv2.WINDOW_AUTOSIZE)\n",
    "#    cropped_img = cv2.resize(cropped, (500, 500))              # Resize image\n",
    "#    cv2.imshow('cropped', cropped_img)\n",
    "    \n",
    "    squares = infer_grid(cropped)\n",
    "#    print(squares)\n",
    "    digits = get_digits(cropped, squares, 28)\n",
    "#    print(digits)\n",
    "    final_image = show_digits(digits)\n",
    "    return final_image\n",
    "\n",
    "def extract_sudoku(image_path):\n",
    "    final_image = parse_grid(image_path)\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ac7f4e-e1b9-42d8-bba8-deba9a7b70a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@20.260] global loadsave.cpp:241 findDecoder imread_('sudoku.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_sudoku \u001b[38;5;241m=\u001b[39m extract_sudoku(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msudoku.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, extracted_sudoku )\n\u001b[1;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 337\u001b[0m, in \u001b[0;36mextract_sudoku\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_sudoku\u001b[39m(image_path):\n\u001b[0;32m--> 337\u001b[0m     final_image \u001b[38;5;241m=\u001b[39m parse_grid(image_path)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_image\n",
      "Cell \u001b[0;32mIn[1], line 316\u001b[0m, in \u001b[0;36mparse_grid\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_grid\u001b[39m(path):\n\u001b[1;32m    315\u001b[0m     original \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m--> 316\u001b[0m     processed \u001b[38;5;241m=\u001b[39m pre_process_image(original)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m#    cv2.namedWindow('processed',cv2.WINDOW_AUTOSIZE)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#    processed_img = cv2.resize(processed, (500, 500))          # Resize image\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m#    cv2.imshow('processed', processed_img)\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     corners \u001b[38;5;241m=\u001b[39m find_corners_of_largest_polygon(processed)\n",
      "Cell \u001b[0;32mIn[1], line 90\u001b[0m, in \u001b[0;36mpre_process_image\u001b[0;34m(img, skip_dilate)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Uses a blurring function, adaptive thresholding and dilation to expose the main features of an image.\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Gaussian blur with a kernal size (height, width) of 9.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Note that kernal sizes must be positive and odd and the kernel must be square.\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m img2 \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     91\u001b[0m proc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(img2, (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m9\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Adaptive threshold using 11 nearest neighbour pixels\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "extracted_sudoku = extract_sudoku(\"sudoku.png\")\n",
    "cv2.imshow(\"image\", extracted_sudoku )\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13698991-8bba-4ef6-a7e1-5892815a2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5f2fa-dc5f-4c3a-9f88-b39127dd6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.load_model('my_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
